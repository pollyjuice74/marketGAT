{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollyjuice74/marketGAT/blob/master/marketGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsBT7hQPl5pW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "!pip install torch-geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.data import TemporalData, HeteroData\n",
        "\n",
        "import os\n",
        "if not os.path.exists('marketGAT'):\n",
        "  pass\n",
        "  !git clone https://github.com/pollyjuice74/marketGAT.git\n",
        "os.chdir('marketGAT')\n",
        "\n",
        "from utils import *\n",
        "from acc import *\n",
        "from model import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HbFsPkTIUvM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9319e21c-59ff-473b-cd8d-08417b2b50eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrying due to error: only integer tensors of a single element can be converted to an index\n",
            "Retrying due to error: only integer tensors of a single element can be converted to an index\n",
            "Retrying due to error: only integer tensors of a single element can be converted to an index\n",
            "Retrying due to error: only integer tensors of a single element can be converted to an index\n",
            "Retrying due to error: only integer tensors of a single element can be converted to an index\n",
            "Retrying due to error: only integer tensors of a single element can be converted to an index\n",
            "Retrying due to error: only integer tensors of a single element can be converted to an index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  buy_price=3.2899999618530273,\n",
              "  SPY={\n",
              "    node_ids=[245],\n",
              "    x_samp=[210, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  TBLA={\n",
              "    node_ids=[245],\n",
              "    x_samp=[210, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  MS={\n",
              "    node_ids=[245],\n",
              "    x_samp=[210, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  PBM={\n",
              "    node_ids=[239],\n",
              "    x_samp=[204, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  TCRX={\n",
              "    node_ids=[245],\n",
              "    x_samp=[210, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  URG={\n",
              "    node_ids=[245],\n",
              "    x_samp=[210, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  UROY={\n",
              "    node_ids=[245],\n",
              "    x_samp=[210, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  UEC={\n",
              "    node_ids=[245],\n",
              "    x_samp=[210, 5],\n",
              "    x_pred=[35, 5],\n",
              "  },\n",
              "  (TBLA, next_in_sequence, TBLA)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 35],\n",
              "  },\n",
              "  (SPY, same_time, TBLA)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 34],\n",
              "  },\n",
              "  (MS, next_in_sequence, MS)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 35],\n",
              "  },\n",
              "  (SPY, same_time, MS)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 34],\n",
              "  },\n",
              "  (PBM, next_in_sequence, PBM)={\n",
              "    edge_index_samp=[2, 204],\n",
              "    edge_index_pred=[2, 35],\n",
              "  },\n",
              "  (SPY, same_time, PBM)={\n",
              "    edge_index_samp=[2, 204],\n",
              "    edge_index_pred=[2, 34],\n",
              "  },\n",
              "  (TCRX, next_in_sequence, TCRX)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 35],\n",
              "  },\n",
              "  (SPY, same_time, TCRX)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 34],\n",
              "  },\n",
              "  (URG, next_in_sequence, URG)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 35],\n",
              "  },\n",
              "  (SPY, same_time, URG)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 34],\n",
              "  },\n",
              "  (UROY, next_in_sequence, UROY)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 35],\n",
              "  },\n",
              "  (SPY, same_time, UROY)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 34],\n",
              "  },\n",
              "  (UEC, next_in_sequence, UEC)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 35],\n",
              "  },\n",
              "  (SPY, same_time, UEC)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 34],\n",
              "  },\n",
              "  (SPY, next_in_sequence, SPY)={\n",
              "    edge_index_samp=[2, 210],\n",
              "    edge_index_pred=[2, 35],\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "endDate = dt.datetime.now()\n",
        "startDate = endDate - dt.timedelta(days=730)\n",
        "n = 18\n",
        "prev_context = 324\n",
        "sample_size = 342 # 324 + 18\n",
        "batch_size = 64\n",
        "alpha = 0.15\n",
        "\n",
        "symbols = ['SPY', 'TBLA', \"MS\", \"PBM\", \"TCRX\", \"URG\", \"UROY\", \"UEC\", \"TBLA\"]#\"AMZN\", \"TSLA\", \"AAPL\", \"GOOGL\", \"META\", \"GM\", \"MS\"]\n",
        "graph = build_graph(symbols, startDate, endDate)\n",
        "\n",
        "sample_graph, curr_ixs = sample(graph, symbols, sample_len=7*30, pred_len=7*5, live=False)\n",
        "sample_graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7pZKqoY3hFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y, time_dict = movement(sample_graph)\n",
        "y, time_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTaxwaOZJ-JP",
        "outputId": "2f30255f-baa8-4460-8bac-154cafdd70c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPY\n",
            "tensor([1.0038, 1.0026, 1.0009, 0.9985, 0.9998, 0.9993, 1.0016, 1.0031, 1.0016,\n",
            "        1.0016, 1.0016, 1.0034, 1.0044, 0.9961, 0.9936, 0.9928, 0.9917, 0.9919,\n",
            "        0.9923, 0.9921, 0.9943, 0.9931, 0.9852, 0.9862, 0.9860, 0.9825, 0.9843,\n",
            "        0.9847, 0.9810, 0.9801, 0.9778, 0.9769, 0.9782, 0.9776, 0.9853])\n",
            "TBLA\n",
            "tensor([1.0182, 1.0137, 1.0137, 1.0061, 1.0030, 1.0030, 1.2766, 1.1368, 1.0881,\n",
            "        1.0805, 1.0821, 1.0638, 1.0684, 1.0441, 1.0410, 1.0334, 1.0243, 1.0410,\n",
            "        1.0471, 1.0578, 1.0851, 1.0790, 1.0471, 1.0502, 1.0380, 1.0289, 1.0304,\n",
            "        1.0350, 1.0426, 1.0380, 1.0304, 1.0304, 1.0274, 1.0274, 1.0361])\n",
            "MS\n",
            "tensor([1.0120, 1.0155, 1.0155, 1.0167, 1.0225, 1.0175, 1.0300, 1.0472, 1.0386,\n",
            "        1.0381, 1.0280, 1.0276, 1.0259, 1.0272, 1.0244, 1.0338, 1.0270, 1.0221,\n",
            "        1.0235, 1.0274, 1.0326, 1.0330, 1.0193, 1.0109, 1.0099, 1.0065, 1.0073,\n",
            "        1.0050, 0.9870, 0.9936, 0.9921, 0.9896, 0.9910, 0.9890, 0.9903])\n",
            "PBM\n",
            "tensor([1.0151, 1.1043, 1.0794, 1.1037, 1.0769, 1.0920, 1.1074, 1.1074, 1.1070,\n",
            "        1.1074, 1.1375, 1.2898, 1.3919, 1.4457, 1.3516, 1.3377, 1.2612, 1.2153,\n",
            "        1.1843, 1.2608, 1.3227, 1.2919, 1.2802, 1.3073, 1.3039, 1.2928, 1.3134,\n",
            "        1.3534, 1.2916, 1.2891, 1.2842, 1.2381, 1.2430, 1.2891, 1.2581])\n",
            "TCRX\n",
            "tensor([1.0000, 1.0043, 1.0129, 1.0169, 1.0287, 1.0301, 1.1320, 1.1062, 1.0961,\n",
            "        1.1047, 1.1076, 1.1047, 1.0976, 1.0828, 1.0488, 1.0481, 1.0473, 1.0567,\n",
            "        1.0531, 1.0617, 1.0961, 1.0762, 1.0438, 1.0352, 1.0215, 1.0086, 1.0072,\n",
            "        1.0273, 1.0344, 1.0158, 1.0115, 1.0029, 0.9986, 1.0029, 1.0172])\n",
            "URG\n",
            "tensor([1.0200, 1.0133, 1.0067, 1.0133, 1.0167, 1.0133, 1.0067, 1.0000, 0.9933,\n",
            "        0.9867, 1.0000, 1.0000, 1.0000, 0.9933, 0.9667, 0.9533, 0.9533, 0.9533,\n",
            "        0.9533, 0.9467, 0.9467, 0.9467, 0.9400, 0.9400, 0.9333, 0.9267, 0.9200,\n",
            "        0.9467, 0.9433, 0.9373, 0.9200, 0.9133, 0.9067, 0.9067, 0.9233])\n",
            "UROY\n",
            "tensor([1.0134, 1.0019, 1.0019, 1.0000, 1.0057, 1.0134, 1.0191, 1.0134, 1.0000,\n",
            "        0.9942, 0.9916, 0.9924, 0.9943, 0.9847, 0.9695, 0.9637, 0.9427, 0.9504,\n",
            "        0.9447, 0.9447, 0.9656, 0.9274, 0.9084, 0.9045, 0.9046, 0.8969, 0.8931,\n",
            "        0.9008, 0.9122, 0.9122, 0.9046, 0.9046, 0.8969, 0.8969, 0.9237])\n",
            "UEC\n",
            "tensor([1.0094, 0.9942, 0.9906, 0.9899, 0.9964, 0.9913, 0.9964, 0.9891, 0.9833,\n",
            "        0.9783, 0.9906, 0.9891, 0.9920, 0.9826, 0.9356, 0.9341, 0.9211, 0.9240,\n",
            "        0.9182, 0.9167, 0.9283, 0.9008, 0.8856, 0.8849, 0.8820, 0.8704, 0.8602,\n",
            "        0.8697, 0.8602, 0.8588, 0.8552, 0.8588, 0.8559, 0.8573, 0.8689])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'SPY': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'TBLA': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'MS': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'PBM': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'TCRX': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'URG': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'UROY': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'UEC': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0.])},\n",
              " {'SPY': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'TBLA': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'MS': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'PBM': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'TCRX': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'URG': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'UROY': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  'UEC': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Module, TransformerEncoder, TransformerEncoderLayer, ModuleList, MultiheadAttention, Linear, Dropout\n",
        "from torch_geometric.nn import GATv2Conv, to_hetero\n",
        "\n",
        "\n",
        "class MarketTransformer(Module):\n",
        "        def __init__(self, metadata, hidden_dims=4*16, num_classes=3, num_heads=8, num_layers=2):\n",
        "                super().__init__()\n",
        "                assert  hidden_dims % num_heads == 0, \"Hidden dims and num_heads don't match\"\n",
        "                self.embedding = torch.nn.Linear(4, hidden_dims) # learned h,l,o,c representations\n",
        "                self.pos_encoder = PositionalEncoder(hidden_dims) # retain temporal order info\n",
        "                self.self_attn = MultiheadAttention(hidden_dims, num_heads) # each stock will attend to itself\n",
        "\n",
        "                self.gat_convs = GATModule(hidden_dims, num_heads, num_layers)\n",
        "\n",
        "                # for capturing relations between different stocks over time\n",
        "                encoder_layers = TransformerEncoderLayer(d_model=hidden_dims, nhead=num_heads)\n",
        "                self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "\n",
        "                # one-hot prediciton of stock's movement\n",
        "                self.classifier = Linear(hidden_dims, num_classes)\n",
        "                # time ix prediction of when the stock will reach pos. returns\n",
        "                self.time_prediction = Linear(hidden_dims, 1)\n",
        "\n",
        "                # turn homogeneous gnn into hetero gnn\n",
        "                self.gat_convs = to_hetero(self.gat_convs, metadata, aggr=\"sum\")\n",
        "\n",
        "        def forward(self, x_dict, edge_index_dict):\n",
        "                for key, x in x_dict.items():\n",
        "                        x = self.embedding(x)\n",
        "                        x = self.pos_encoder(x)\n",
        "                        x_dict[key], _ = self.self_attn(x,x,x)\n",
        "\n",
        "                for conv in self.gat_convs:\n",
        "                        x_dict = conv(x_dict, edge_index_dict)\n",
        "\n",
        "                x, mask = self._to_transformer_input(x_dict)\n",
        "                x = self.transformer_encoder(x, mask)\n",
        "\n",
        "                class_out_dict, time_out_dict = dict(), dict()\n",
        "                for key in x_dict.keys():\n",
        "                        class_out_dict[key] = self.classifier(x)\n",
        "                        time_out_dict[key] = self.time_prediction(x)\n",
        "\n",
        "                return out_dict\n",
        "\n",
        "        def _to_transformer_input(self, x_dict):\n",
        "                ### TODO\n",
        "                all_x, mask = [], []\n",
        "                return x, mask\n",
        "\n",
        "        def compute_utility(class_out_dict, time_out_dict):\n",
        "                utility_dict = dict()\n",
        "                for key in class_out_dict.keys():\n",
        "                        P_return = torch.softmax(class_out_dict[key])\n",
        "                        utility_dict[key] = P_return / time_out_dict[key]\n",
        "                return utility_dict\n",
        "\n",
        "        def select_top_stocks():\n",
        "                pass\n",
        "\n",
        "\n",
        "class GATModule(Module):\n",
        "        def __init__(self, hidden_dims, num_heads, num_layers):\n",
        "                super().__init__()\n",
        "                self.gat_convs = ModuleList() # utilize graph structure of the data\n",
        "                for _ in range(num_layers):\n",
        "                        self.gat_convs.append( GATv2Conv(hidden_dims, hidden_dims//num_heads, heads=num_heads, add_self_loops=False) )\n",
        "\n",
        "        def forward(self, x_dict, edge_index_dict):\n",
        "                for conv in self.gat_convs:\n",
        "                        x_dict = conv(x_dict, edge_index_dict)\n",
        "                return x_dict\n",
        "\n",
        "\n",
        "class PositionalEncoder(Module):\n",
        "        def __init__(self, d_model, max_len=5000):\n",
        "                super().__init__()\n",
        "                pe = torch.zeros(max_len, d_model)\n",
        "                position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "                div_term = torch.exp( torch.arange(0, d_model, 2).float() * (-torch.log( torch.tensor(1e5) ) / d_model) )\n",
        "                pe[:, 0::2] = torch.sin(position * div_term)\n",
        "                pe[:, 1::2] = torch.cos(position * div_term)\n",
        "                self.register_buffer( 'pe', pe.unsqueeze(0).transpose(0,1) )\n",
        "\n",
        "                self.dropout = Dropout(0.1)\n",
        "\n",
        "        def forward(self, x):\n",
        "                x = x + pe[:x.size(0), :]\n",
        "                return self.dropout(x)\n",
        "\n",
        "\n",
        "# (s, p)->(s, p/m + f/v, k+u, d)->(s, k+u)->(s, u)->(s,1)->(1,)"
      ],
      "metadata": {
        "id": "k7S1s2jg4fvM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vq6BwmOWdd4Q",
        "outputId": "19b42cfc-a0a7-42b6-ea9c-fdcd129f9394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  SPY={\n",
            "    x=[3497, 4],\n",
            "    t=[3498, 1],\n",
            "    node_ids=[3498],\n",
            "  },\n",
            "  TBLA={\n",
            "    x=[3497, 4],\n",
            "    t=[3498, 1],\n",
            "    node_ids=[3498],\n",
            "  },\n",
            "  MS={\n",
            "    x=[3497, 4],\n",
            "    t=[3498, 1],\n",
            "    node_ids=[3498],\n",
            "  },\n",
            "  PBM={\n",
            "    x=[924, 4],\n",
            "    t=[925, 1],\n",
            "    node_ids=[925],\n",
            "  },\n",
            "  TCRX={\n",
            "    x=[3242, 4],\n",
            "    t=[3243, 1],\n",
            "    node_ids=[3243],\n",
            "  },\n",
            "  URG={\n",
            "    x=[3497, 4],\n",
            "    t=[3498, 1],\n",
            "    node_ids=[3498],\n",
            "  },\n",
            "  UROY={\n",
            "    x=[3497, 4],\n",
            "    t=[3498, 1],\n",
            "    node_ids=[3498],\n",
            "  },\n",
            "  UEC={\n",
            "    x=[3497, 4],\n",
            "    t=[3498, 1],\n",
            "    node_ids=[3498],\n",
            "  },\n",
            "  (SPY, next_in_sequence, SPY)={ edge_index=[2, 3496] },\n",
            "  (TBLA, next_in_sequence, TBLA)={ edge_index=[2, 3496] },\n",
            "  (MS, next_in_sequence, MS)={ edge_index=[2, 3496] },\n",
            "  (PBM, next_in_sequence, PBM)={ edge_index=[2, 923] },\n",
            "  (TCRX, next_in_sequence, TCRX)={ edge_index=[2, 3241] },\n",
            "  (URG, next_in_sequence, URG)={ edge_index=[2, 3496] },\n",
            "  (UROY, next_in_sequence, UROY)={ edge_index=[2, 3496] },\n",
            "  (UEC, next_in_sequence, UEC)={ edge_index=[2, 3496] },\n",
            "  (SPY, same_time, SPY)={ edge_index=[2, 3498] },\n",
            "  (SPY, same_time, TBLA)={ edge_index=[2, 3498] },\n",
            "  (SPY, same_time, MS)={ edge_index=[2, 3498] },\n",
            "  (SPY, same_time, PBM)={ edge_index=[2, 925] },\n",
            "  (SPY, same_time, TCRX)={ edge_index=[2, 3243] },\n",
            "  (SPY, same_time, URG)={ edge_index=[2, 3498] },\n",
            "  (SPY, same_time, UROY)={ edge_index=[2, 3498] },\n",
            "  (SPY, same_time, UEC)={ edge_index=[2, 3498] }\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Graph for symbol S does not have 'node_ids'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7b1289841660>\u001b[0m in \u001b[0;36m<cell line: 516>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7b1289841660>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hidden_dims, epochs, learning_rate, live)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_bets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msym\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'SPY'\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# sym: [(amount in $, shares), ..., ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# Graphs of stocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarketTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7b1289841660>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_bets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msym\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'SPY'\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# sym: [(amount in $, shares), ..., ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# Graphs of stocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarketTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7b1289841660>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sym, live, graph)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7b1289841660>\u001b[0m in \u001b[0;36minitialize_graph\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_live\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7b1289841660>\u001b[0m in \u001b[0;36msample\u001b[0;34m(graph, symbols, sample_len, pred_len, live)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m# Check if `node_ids` exist for the current symbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'node_ids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Graph for symbol {sym} does not have 'node_ids'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m# stock nodes ixs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Graph for symbol S does not have 'node_ids'."
          ]
        }
      ],
      "source": [
        "# Suppose\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# from model import *\n",
        "# from utils import *\n",
        "\n",
        "\n",
        "def sample(graph, symbols, sample_len, pred_len, live):\n",
        "    sample_graph = HeteroData()\n",
        "\n",
        "    while True:\n",
        "        # try:\n",
        "            # random SPY sample index\n",
        "            spy_ix = torch.randint(0, graph['SPY'].x.size(0) - sample_len - pred_len, (1,)) if not live else int(graph['SPY'].x.size(0) - sample_len - pred_len)\n",
        "            curr_ix = spy_ix + sample_len\n",
        "\n",
        "            # print( graph['SPY'].t.shape)\n",
        "            # SPY graph\n",
        "            sample_graph['SPY'].x = torch.cat([graph['SPY'].x[spy_ix:curr_ix + pred_len],\n",
        "                                              graph['SPY'].t[spy_ix:curr_ix + pred_len]], dim=1)\n",
        "            sample_graph['SPY'].node_ids = graph['SPY'].node_ids[spy_ix:curr_ix + pred_len]\n",
        "\n",
        "            # SPY nodesIDs\n",
        "            first_nodeID = graph['SPY'].node_ids[spy_ix]\n",
        "            curr_nodeID = graph['SPY'].node_ids[curr_ix]\n",
        "            last_nodeID = graph['SPY'].node_ids[curr_ix + pred_len]\n",
        "\n",
        "            # SPY edges\n",
        "            spy_edges = graph['SPY', 'next_in_sequence', 'SPY'].edge_index[:, spy_ix:curr_ix + pred_len] ###\n",
        "\n",
        "            for sym in symbols:\n",
        "                if sym == 'SPY':\n",
        "                  continue\n",
        "\n",
        "                print(graph)\n",
        "                # Check if `node_ids` exist for the current symbol\n",
        "                if not hasattr(graph[sym], 'node_ids'):\n",
        "                    raise AttributeError(f\"Graph for symbol {sym} does not have 'node_ids'.\")\n",
        "\n",
        "                # stock nodes ixs\n",
        "                f_sym_ix = torch.where(graph[sym].node_ids == first_nodeID.item())[0] # First\n",
        "                c_sym_ix = torch.where(graph[sym].node_ids == curr_nodeID.item())[0] # Current\n",
        "                l_sym_ix = torch.where(graph[sym].node_ids == last_nodeID.item())[0] # Last\n",
        "\n",
        "                # stock graph\n",
        "                sample_graph[sym].x = torch.cat([graph[sym].x[f_sym_ix:l_sym_ix],\n",
        "                                                graph[sym].t[f_sym_ix:l_sym_ix]], dim=1)\n",
        "                sample_graph[sym].node_ids = graph[sym].node_ids[f_sym_ix:l_sym_ix]\n",
        "\n",
        "                # stock edges\n",
        "                sym_edges = graph[sym, 'next_in_sequence', sym].edge_index[:, f_sym_ix:l_sym_ix] ###\n",
        "                same_time_edges =  graph['SPY', 'same_time', sym].edge_index[:, f_sym_ix:l_sym_ix -1] ###\n",
        "\n",
        "                dicts, edge_ixs = make_dicts([spy_edges, sym_edges]) # spy, sym\n",
        "                same_time_edges = same_time_ix(same_time_edges, dicts) # convert same time ixs from graph ixs to sample graph ixs\n",
        "                # print(same_time_edges)\n",
        "\n",
        "                # set edges\n",
        "                sample_graph[sym, 'next_in_sequence', sym].edge_index = edge_ixs[1]\n",
        "                sample_graph['SPY', 'same_time', sym].edge_index = same_time_edges\n",
        "\n",
        "                # normalize stock data and split into sample and pred\n",
        "                sample_graph[sym].x_samp, sample_graph[sym].x_pred, buy_price = normalize(sample_graph[sym].x, curr_ix=c_sym_ix - f_sym_ix, pred_ix=l_sym_ix - f_sym_ix) # shifts ixs by first stock ix\n",
        "\n",
        "                sample_graph.buy_price = buy_price\n",
        "\n",
        "                # split edges into sample and pred\n",
        "                sample_graph[sym, 'next_in_sequence', sym].edge_index_samp = sample_graph[sym, 'next_in_sequence', sym].edge_index[:, :c_sym_ix - f_sym_ix]\n",
        "                sample_graph[sym, 'next_in_sequence', sym].edge_index_pred = sample_graph[sym, 'next_in_sequence', sym].edge_index[:, c_sym_ix - f_sym_ix:l_sym_ix - f_sym_ix+1]\n",
        "\n",
        "                sample_graph['SPY', 'same_time', sym].edge_index_samp = sample_graph['SPY', 'same_time', sym].edge_index[:, :c_sym_ix - f_sym_ix]\n",
        "                sample_graph['SPY', 'same_time', sym].edge_index_pred = sample_graph['SPY', 'same_time', sym].edge_index[:, c_sym_ix - f_sym_ix:l_sym_ix - f_sym_ix+1]\n",
        "                # print(sample_graph[sym, 'next_in_sequence', sym].edge_index_samp)\n",
        "\n",
        "            # set SPY edges, normalize SPY data and split into sample and pred\n",
        "            sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index = edge_ixs[0]\n",
        "            sample_graph['SPY'].x_samp, sample_graph['SPY'].x_pred, _ = normalize(sample_graph['SPY'].x, curr_ix=curr_ix - spy_ix, pred_ix=curr_ix+pred_len - spy_ix) # shifts ixs by first spy stock ix\n",
        "\n",
        "            # split 'next_in_sequence' edges into sample and pred\n",
        "            sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index_samp = sample_graph[sym, 'next_in_sequence', sym].edge_index[:, :curr_ix - spy_ix]\n",
        "            sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index_pred = sample_graph[sym, 'next_in_sequence', sym].edge_index[:, curr_ix - spy_ix:curr_ix+pred_len - spy_ix + 1]\n",
        "            # print(sample_graph['SPY'].x_pred)\n",
        "\n",
        "            # REMOVE REDUNDANT sample_graph.x #\n",
        "            del sample_graph['SPY'].x\n",
        "            del sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index\n",
        "\n",
        "            for sym in symbols:\n",
        "              if sym == 'SPY':\n",
        "                continue\n",
        "\n",
        "              del sample_graph[sym].x\n",
        "              del sample_graph[sym, 'next_in_sequence', sym].edge_index\n",
        "              del sample_graph['SPY', 'same_time', sym].edge_index\n",
        "\n",
        "            if live:\n",
        "                return sample_graph, spy_ix\n",
        "            else:\n",
        "                curr_ixs = {sym: len(sample_graph[sym].x_samp) for sym in symbols}\n",
        "                return sample_graph, curr_ixs\n",
        "\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Retrying due to error: {e}\")\n",
        "        #     continue\n",
        "\n",
        "\n",
        "class Stock:\n",
        "    def __init__(self, sym, live, graph):\n",
        "        # Metadata\n",
        "        self.price = None # setted with live_price\n",
        "        self.trailing_data = [None, 0]#, None] # trailing_price, active, used_ix\n",
        "        self.live = live\n",
        "        self.sym = sym\n",
        "        # Graph\n",
        "        self.sample_len = 7*30 # 7h * 30d\n",
        "        self.pred_len = 7*5 # 7h * 5d\n",
        "        self.sample_graph = None\n",
        "        self.ix = None\n",
        "        self.pct = None\n",
        "\n",
        "        self.initialize_graph(graph)\n",
        "        ########################\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Updates price, gets either the live price or the price\n",
        "        at the current step of the sample_graph data object.\n",
        "        \"\"\"\n",
        "        if self.live:\n",
        "          price =  self.live_price()[0][2]\n",
        "        else:\n",
        "          #print(self.sample_graph[self.sym].x_pred)\n",
        "          price = self.sample_graph[self.sym].x_samp[-1, 2].item() * self.sample_graph.buy_price\n",
        "          print(\"Updated:\", price, self.sym)\n",
        "\n",
        "        self.price = price\n",
        "\n",
        "\n",
        "    def live_price(self, interval='1m'):\n",
        "        \"\"\" Gets info and sets live price of stock \"\"\"\n",
        "        s = yf.Ticker(self.sym)\n",
        "        df = s.history(period='1d', interval=interval).iloc[-1]\n",
        "\n",
        "        self.price = float(df['Close'].item()) # CLOSE price set as LIVE PRICE\n",
        "\n",
        "        x =  torch.tensor(df[['High', 'Low', 'Close', 'Open']])\n",
        "        t = None #df.index.strftime('%H%M%S').astype('int64')\n",
        "        node_ids = None #torch.tensor(df.index.strftime('%Y%m%d%H%M%S').astype('int64'), dtype=torch.int64)\n",
        "\n",
        "        return (x, t, node_ids)  # x,t,node_ids,edge_index\n",
        "\n",
        "\n",
        "    def sample_live(self, graph, sym): ###\n",
        "        \"\"\" Sample live stock prices \"\"\"\n",
        "        self.update() # sets live price\n",
        "\n",
        "        sample_graph, ix = sample(graph, sym, self.sample_len, self.pred_len, live=self.live)\n",
        "        return sample_graph, ix\n",
        "\n",
        "\n",
        "    def initialize_graph(self, graph):\n",
        "        \"\"\" Initialize sample_graph, ix, pct and price \"\"\"\n",
        "        if self.live:\n",
        "            self.sample_graph, self.ix = self.sample_live(graph, self.sym)\n",
        "        else:\n",
        "            self.sample_graph, self.ix = sample(graph, self.sym, self.sample_len, self.pred_len, self.live)\n",
        "            self.update()\n",
        "\n",
        "        pct = None\n",
        "        self.pct = pct\n",
        "\n",
        "        self.trailing_data[0] = self.sample_graph.buy_price # missing used_ix\n",
        "\n",
        "\n",
        "class Account:\n",
        "    def __init__(self, hidden_dims=7*30, epochs=2000, learning_rate=1e-05, live=False):\n",
        "        # Account info\n",
        "        self.history = list() # Tape of transaction history\n",
        "        self.net_value = 416.29\n",
        "        self.portions = None # [1, 8]\n",
        "        self.used = None # [1, 8]\n",
        "        self.bets = 2 # Limited ammount of bets per day\n",
        "        # Data\n",
        "        self.symbols = ['SPY', 'TBLA', \"MS\", \"PBM\", \"TCRX\", \"URG\", \"UROY\", \"UEC\", \"TBLA\"]#\"AMZN\", \"TSLA\", \"AAPL\", \"GOOGL\", \"META\", \"GM\", \"MS\"]\n",
        "        self.graph = build_graph(self.symbols, startDate, endDate)\n",
        "        self.sample_graph = None\n",
        "        # Bets\n",
        "        self.live = live\n",
        "        self.current_bets = {sym: [] for sym in self.symbols if sym != 'SPY'} # sym: [(amount in $, shares), ..., ]\n",
        "        self.stocks = {sym: Stock(sym, live=live, graph=self.graph) for sym in self.symbols} # Graphs of stocks\n",
        "        # Model\n",
        "        self.model = MarketTransformer(metadata=self.graph.metadata())\n",
        "        # Training\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        ##################################################\n",
        "\n",
        "\n",
        "    def get_portion(self):\n",
        "        \"\"\"\n",
        "        Portions out the Account.net_value as follows:\n",
        "\n",
        "            Tithe:\n",
        "                10% - Always cash\n",
        "            Investment Capital:\n",
        "                90% - Divided into 8 portions of 11.25% each (90/8)\n",
        "        \"\"\"\n",
        "\n",
        "        if self.portions is None:\n",
        "            inv_cap = self.net_value * 0.9 # Investment capital is 90%\n",
        "            self.net_value -= inv_cap\n",
        "\n",
        "            self.portions = torch.tensor([inv_cap / 8 for _ in range(8)], dtype=torch.float) # [1, 8]\n",
        "            self.used = torch.zeros_like(self.portions)\n",
        "\n",
        "\n",
        "\n",
        "        ixs = (self.used==0).nonzero(as_tuple=True)[0].tolist()# first portion that != 0 or negative,\n",
        "        ix = random.choice(ixs)\n",
        "        amount = torch.clone(self.portions[ix]) # select amount $\n",
        "\n",
        "        self.portions[ix] -= amount.item() # to 0\n",
        "        print(\"GET PORTION: \", self.portions, amount, ix)\n",
        "        self.used[ix] = 1 # mark used vector\n",
        "\n",
        "        return amount, ix\n",
        "\n",
        "\n",
        "    def buy(self, sym, amount, ix):\n",
        "        \"\"\"\n",
        "        Buys stock of a symbol given the amount of $ provided by the ix'th portion.\n",
        "\n",
        "        Updates:\n",
        "            self.stocks\n",
        "            self.current_bets\n",
        "            self.history\n",
        "            self.portions\n",
        "        \"\"\"\n",
        "        stock = self.stocks[sym]\n",
        "\n",
        "        stock.update()\n",
        "        price = stock.price\n",
        "\n",
        "        if amount > price:\n",
        "          shares = int(amount / price)\n",
        "          left_over = (amount % price).item()\n",
        "        else:\n",
        "          print(sym, \" stock price too high \", price, \" for amount \", amount.item())\n",
        "          self.portions[ix] += amount\n",
        "          self.used[ix] = 0\n",
        "          return\n",
        "\n",
        "        # print(shares * stock.price, shares, ix)\n",
        "        self.current_bets[sym].append((shares * price, shares, ix)) # sym: amount in stocks owned\n",
        "\n",
        "        self.history.append((shares * price, shares, ix, 'Buy'))\n",
        "\n",
        "        print(\"BUYING: \", sym, \" for \", shares*price, \" with \", left_over, \" left over.\")\n",
        "        self.portions[ix] += left_over\n",
        "\n",
        "\n",
        "    def sell(self, sym):\n",
        "        \"\"\"\n",
        "        Sells all stock portions of a given symbol at the current stock price\n",
        "        and update portions accordingly.\n",
        "\n",
        "        Updates:\n",
        "            self.used\n",
        "            self.portions\n",
        "            self.history\n",
        "            self.current_bets\n",
        "        \"\"\"\n",
        "        stock = self.stocks[sym]\n",
        "        stock.update()\n",
        "\n",
        "        for purchase_am, shares, ix in self.current_bets[sym]:\n",
        "            self.used[ix] = 0 # set used vector space free\n",
        "            self.portions[ix] += shares * stock.price\n",
        "\n",
        "            self.history.append((shares * stock.price, shares, ix, 'Sell'))\n",
        "            print(\"SOLD: \", sym, \" for \", shares*stock.price, \"*******************************************************************************************************************************************************************************************************************\")\n",
        "\n",
        "        self.current_bets[sym] = list() # remove bet\n",
        "\n",
        "\n",
        "    def wait(self):\n",
        "        \"\"\" Wait some time before continuing \"\"\"\n",
        "        time.sleep(10)\n",
        "\n",
        "\n",
        "    def buy_conditions(self, pred):\n",
        "        \"\"\" Test if preditction is for upward movement \"\"\"\n",
        "        return torch.equal(pred, torch.tensor([1,0,0]))\n",
        "\n",
        "\n",
        "    def rank(self, ):\n",
        "        \"\"\"\n",
        "        Ranks stock symbols by most to least profitable given a x day interval.\n",
        "\n",
        "        The ranking occurs through simulated trading of the x day interval where\n",
        "        the 'model' buys a stock if it\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def print(self, i, epoch_loss, freq=25):\n",
        "        \"\"\" Prints epoch and loss data \"\"\"\n",
        "        if i % freq == 0:\n",
        "            print(f\"Epoch: {i+1}/{self.epochs}, Loss: {epoch_loss}\")\n",
        "\n",
        "\n",
        "    def test(self): # Live trading simulation\n",
        "        \"\"\"\n",
        "        Simulates the model predicting movement of the stocks given a sample interval\n",
        "        and awaits for it to sell before beggining the process again.\n",
        "\n",
        "        Goes in sequential order of a larger sample interval of a stock's history\n",
        "        and gives a profitablility calculation based on model predictions.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "\n",
        "          # Checks for buying conditions in all symbols\n",
        "          for sym in [sym for sym, curr_bets in self.current_bets.items() if not curr_bets and sym != 'SPY']: #self.symbols:\n",
        "              print(\"Checking for buying conditions: \", sym)\n",
        "\n",
        "              stock = self.stocks[sym]\n",
        "              stock.pct = torch.std(stock.sample_graph[sym].x_samp) * 0.5 # try to predict a half std dev movement\n",
        "\n",
        "              # Train model\n",
        "              ################################\n",
        "              # latest = stock.live_price()[0][2] if self.live else sample_graph[sym].x_pred[0]\n",
        "\n",
        "              y = torch.tensor([1, 0, 0]) #movement(latest, pct=stock.pct.item())\n",
        "              pred = torch.clone(y) #self.model(sample_graph, pct=stock.pct)\n",
        "\n",
        "              # loss = self.criterion(pred, y)\n",
        "\n",
        "              # self.optimizer.zero_grad(set_to_none=True)\n",
        "              # loss.backward()\n",
        "              # self.optimizer.step()\n",
        "              ################################\n",
        "\n",
        "              if self.buy_conditions(pred):\n",
        "                  if self.used != None and torch.all(self.used.bool()):\n",
        "                    print(\"No more portions left.\")\n",
        "                    break\n",
        "\n",
        "                  amount, used_ix = self.get_portion()\n",
        "                  self.buy(sym, amount, used_ix) #if ix is None\n",
        "\n",
        "          ### Inbetween period ######\n",
        "          if self.live:\n",
        "            self.wait()\n",
        "\n",
        "          self.update_graph()\n",
        "          ###########################\n",
        "\n",
        "          # Checks for selling conditions in all symbols\n",
        "          for sym in self.symbols:\n",
        "              if sym == 'SPY':\n",
        "                continue\n",
        "\n",
        "              stock = self.stocks[sym]\n",
        "              print(\"Monitoring: \", sym, \"at \", stock.pct.item()*100, \"%\")\n",
        "\n",
        "              # Sell at profit or sell at the end of the prediction time\n",
        "              #print(stock.sample_graph[sym].x_pred, torch.any(stock.sample_graph[sym].x_pred))\n",
        "              if self.pull_back(sym) or not torch.any(stock.sample_graph[sym].x_pred): # x_pred != empty\n",
        "                  self.sell(sym) # sells all stocks owned of that symbol\n",
        "\n",
        "                  if not torch.any(stock.sample_graph[sym].x_pred):\n",
        "                    stock.sample_graph, stock.ix = sample(self.graph, sym, stock.sample_len, stock.pred_len, live=self.live)\n",
        "                    self.stocks[sym] = stock # save new sample_graph\n",
        "\n",
        "\n",
        "          self.print_acc()\n",
        "\n",
        "\n",
        "    def print_acc(self):\n",
        "        \"\"\" Print info for the account \"\"\"\n",
        "\n",
        "        if self.portions != None:\n",
        "          net_val = self.net_value + torch.sum(self.portions) + sum([bet[0] for sym, bets in self.current_bets.items() for bet in bets])\n",
        "        else:\n",
        "          net_val = self.net_value\n",
        "\n",
        "        for stock in self.stocks.values():\n",
        "          if stock is not None:\n",
        "              stock.update()\n",
        "\n",
        "        print(\n",
        "              f\"\"\"\n",
        "                Account net_value: {net_val}\\n\n",
        "\n",
        "                Portions:\n",
        "                {self.portions}\\n\n",
        "                Used:\n",
        "                {self.used}\\n\n",
        "\n",
        "                Current bets: {self.current_bets}\\n\n",
        "                Trailing prices:\\n\n",
        "                { {sym: stock.trailing_data[0] for sym, stock in self.stocks.items() if stock != None and sym != 'SPY'} }\n",
        "\n",
        "                LIVE PRICES:\n",
        "                { {sym: stock.price for sym, stock in self.stocks.items() if stock is not None} }\n",
        "                \"\"\"\n",
        "        )\n",
        "\n",
        "\n",
        "    def update_graph(self): ###\n",
        "        \"\"\"\n",
        "        Update graph to append live stock prices\n",
        "        or step each stock's sample_graph\n",
        "        \"\"\"\n",
        "        if self.live:\n",
        "          for sym in self.graph.metadata()[0]:\n",
        "            stock = self.stocks[sym]\n",
        "            x, t, node_ids = stock.live_price()\n",
        "\n",
        "            _, ix = self.graph[sym, 'next_in_sequence', sym].edge_index[:, -1]\n",
        "            ix = ix.item()\n",
        "            edge_index = torch.tensor([[ix],\n",
        "                                       [ix+1],])\n",
        "\n",
        "            # x, t, node_ids, edge_index\n",
        "            self.graph[sym].x = torch.cat([self.graph[sym].x, x.unsqueeze(0)], dim=0)\n",
        "            self.graph[sym].edge_index = torch.cat([self.graph[sym, 'next_in_sequence', sym].edge_index, edge_index], dim=1)\n",
        "            # self.graph[sym].t = torch.cat([self.graph[sym].t, t])\n",
        "            # self.graph[sym].node_ids = torch.cat([self.graph[sym].node_ids, node_ids])\n",
        "\n",
        "        else:\n",
        "          for sym in self.graph.metadata()[0]:\n",
        "            stock = self.stocks[sym]\n",
        "\n",
        "            if stock.ix < stock.sample_graph['SPY', 'same_time', sym].edge_index.shape[1]:\n",
        "              stock.sample_graph, stock.ix = step(stock.sample_graph, stock.ix-1, sym)\n",
        "              self.stocks[sym] = stock # update stocks\n",
        "\n",
        "              stock.update()\n",
        "\n",
        "\n",
        "    def pull_back(self, sym, pull=0.02):\n",
        "        \"\"\"\n",
        "        Implements pull-back trading where you trail the price\n",
        "        so it won't drop past a certain percent change since it's peak.\n",
        "\n",
        "        target_price [float]: peak price achieved\n",
        "        pull [float]: pull back percent from target_price\n",
        "        \"\"\"\n",
        "        stock = self.stocks[sym]\n",
        "\n",
        "        trailing_price, active = stock.trailing_data\n",
        "        target_price = stock.sample_graph.buy_price * (1+stock.pct) # buy_price * 1.03\n",
        "\n",
        "        if trailing_price is None:\n",
        "            stock.trailing_data[0] = trailing_price = target_price.item()\n",
        "\n",
        "        if stock.price >= target_price or active:\n",
        "            #print(stock.trailing_data)\n",
        "            stock.trailing_data[1] = 1 # set 'active' True\n",
        "\n",
        "            if stock.price < trailing_price * (1-pull): # SELL CONDITION\n",
        "                stock.trailing_data = [None, 0] # reset symbol's trailing price once sold\n",
        "                return True\n",
        "\n",
        "            if stock.price > trailing_price:\n",
        "                #print(stock.trailing_data)\n",
        "                stock.trailing_data[0] = stock.price # update 'trailing_price'\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Trains model to predict a one hot label of size [1, 3]\n",
        "        corresponding to the stock's movement given a x day interval.\n",
        "        \"\"\"\n",
        "        print(\"***\")\n",
        "        for i in range(self.epochs):\n",
        "            epoch_loss = 0\n",
        "\n",
        "            for _ in range(100): # sample 100 times\n",
        "                print(self.symbols)\n",
        "                sample_graph, curr_ixs = sample(self.graph, self.symbols, sample_len=self.sample_len, pred_len=self.pred_len, live=False) # Samples Training graph nodes\n",
        "                curr_ixs = None\n",
        "\n",
        "                while sample_graph['SPY'].x_pred.numel() > 0: # while there is more data to predict\n",
        "                    y_hat_dict, time_dict_hat = self.model(sample_graph.x_samp_dict, sample_graph.edge_index_samp_dict) ###\n",
        "                    y_dict, time_dict = movement(sample_graph[sym].x_pred[0], pct=pct.item())\n",
        "\n",
        "                    # Calculate pct chg and time pred loss for each sym\n",
        "                    for sym in sample_graph.node_types:\n",
        "                        loss_y = self.criterion(y_hat_dict[sym], y_dict[sym])\n",
        "                        loss_time = self.criterion(time_dict_hat[sym], time_dict[sym])\n",
        "                        loss = loss_y + loss_time\n",
        "\n",
        "                        epoch_loss += loss.item()\n",
        "\n",
        "                        # Backward pass\n",
        "                        self.optimizer.zero_grad(set_to_none=True)\n",
        "                        loss.backward()\n",
        "                        self.optimizer.step()\n",
        "\n",
        "                    curr_ixs = step(sample_graph, curr_ixs, sym)\n",
        "\n",
        "            self.print(i, epoch_loss, freq=25)\n",
        "\n",
        "\n",
        "acc = Account()\n",
        "acc.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHMqToeTzRdH"
      },
      "outputs": [],
      "source": [
        "#graph = build_graph(['AMZN', 'MSFT', 'TCRX'])\n",
        "sample_graph, ix = sample(graph, sym)\n",
        "\n",
        "\n",
        "#def sample_edges(sym):\n",
        "\n",
        "# Symbol edges #\n",
        "x_samp_len = sample_graph[sym].x_samp.shape[0]\n",
        "ix = (sample_graph[sym, 'next_in_sequence', sym].edge_index == x_samp_len).nonzero(as_tuple=False)[0,1].item()\n",
        "\n",
        "# set edges\n",
        "edge_index_samp = sample_graph[sym, 'next_in_sequence', sym].edge_index[:, :ix-1]\n",
        "edge_index_samp = torch.cat((edge_index_samp[:, 0].unsqueeze(1), edge_index_samp), dim=1) # mask dim\n",
        "\n",
        "edge_index_pred = sample_graph[sym, 'next_in_sequence', sym].edge_index[:, ix-1:-1]\n",
        "\n",
        "\n",
        "# SPY edges #\n",
        "same_time = sample_graph['SPY', 'same_time', sym].edge_index\n",
        "#print(same_time)\n",
        "\n",
        "sp_same_ix, sym_ix = (same_time  == x_samp_len).nonzero(as_tuple=False)[:, 1].tolist()\n",
        "sp_ix = (sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index == sp_same_ix).nonzero(as_tuple=False)[0,1].item()\n",
        "print(sp_same_ix, sym_ix, sp_ix)\n",
        "\n",
        "sp_ei_samp = sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index[:, :sp_ix] ###\n",
        "sp_ei_pred = sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index[:, sp_ix:] ###\n",
        "print(sp_ei_samp.shape, sp_ei_pred.shape)\n",
        "\n",
        "sample_same_time = same_time[:, :sym_ix]\n",
        "print(sample_same_time.shape, x_samp_len)\n",
        "\n",
        "\n",
        "\n",
        "spy = sample_graph['SPY']\n",
        "symb = sample_graph[sym]\n",
        "print(sample_graph)\n",
        "\n",
        "\n",
        "print([x.shape for k, x in symb.items()], [x.shape for k, x in spy.items()]) #edge_index_samp.shape, edge_index_pred.shape)\n",
        "      #sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index)\n",
        "#sample_graph['SPY', 'same_time', sym].edge_index = same_time_edges\n",
        "\n",
        "# normalize stock data\n",
        "ix, sample_graph[sym].x_samp.shape[0], sample_graph[sym].x_pred.shape, sample_graph['SPY'].x_samp.shape, sample_graph['SPY'].x_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWYOT69bvgqh"
      },
      "outputs": [],
      "source": [
        "sym = 'TCRX'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "graph = build_graph(['AMZN', 'MSFT', 'TCRX'])\n",
        "print(graph.node_types)\n",
        "sample_graph, ix = sample(graph, sym)\n",
        "\n",
        "sample_graph.x_samp_dict\n",
        "sample_graph.edge_index_dict\n",
        "\n",
        "\n",
        "\n",
        "# make edge index with sample graph ixs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# sample edges\n",
        "# sample_graph[sym, 'next_in_sequence', sym].edge_index = graph[sym][sym, 'next_in_sequence', sym].edge_index[:, s_ix:curr_ix + pred_len] ###\n",
        "# sample_graph['SPY', 'next_in_sequence', 'SPY'].edge_index = graph['SPY']['SPY', 'next_in_sequence', 'SPY'].edge_index[:, f_sp_ix:l_sp_ix] ###\n",
        "# sample_graph['SPY', 'same_time', sym].edge_index =  graph['SPY', 'same_time', sym].edge_index[:, s_ix:curr_ix + pred_len] ###\n",
        "\n",
        "# print(sample_graph['SPY'].x_samp.shape, ix)\n",
        "# Check\n",
        "# sp_ix_raw, s_ix_raw = sample_graph['SPY', 'same_time', sym][:, ix]\n",
        "# graph[sym][sym].node_ids[s_ix_raw] == graph['SPY']['SPY'].node_ids[sp_ix_raw]\n",
        "\n",
        "#sample_graph[sym].x_samp, sample_graph[sym].x_pred = step(sample_graph[sym].x_samp, sample_graph[sym].x_pred)\n",
        "#print(sample_graph[sym].x_samp, sample_graph[sym].x_pred)\n",
        "# print(sample_graph['SPY', 'same_time', sym][:, ix])\n",
        "# print(sample_graph['SPY', 'next_in_sequence', 'SPY']['edge_index'][0])\n",
        "\n",
        "# sp_y = movement(sp_x_pred, pct=0.003)\n",
        "# stock_y = movement(stock_x_samp, pct=0.003)\n",
        "\n",
        "# while len(sample_graph['SPY'].x_pred):\n",
        "#   ix = step(sample_graph, ix, sym)\n",
        "#   s_ix = len(sample_graph[sym].x_samp)\n",
        "#   sp_ix = len(sample_graph['SPY'].x_samp)\n",
        "#   print(s_ix, sp_ix)\n",
        "#   print(sample_graph['SPY'].node_ids[sp_ix] == sample_graph[sym].node_ids[s_ix])\n",
        "#   print(sample_graph['SPY'].node_ids[sp_ix], sample_graph[sym].node_ids[s_ix])\n",
        "\n",
        "# print(sample_graph['SPY'].x_samp, sample_graph['SPY'].x_pred)\n",
        "# print(sample_graph)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM74jZ6vHw3q5IjpWNWzq41",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}